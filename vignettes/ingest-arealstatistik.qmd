---
title: Ingest Swiss Arealstatistik LULC Data
author: Jan Hartman
date: 2025-10-16
vignette: >
  %\VignetteIndexEntry{evoland-plus-ingest-arealstatistik}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
execute:
  enabled: false
---

This file shows how to ingest [Arealstatistik (AS)](https://www.bfs.admin.ch/bfs/de/home/dienstleistungen/geostat/geodaten-bundesstatistik/boden-nutzung-bedeckung-eignung/arealstatistik-schweiz.html) data into an evoland database.

In order to read in land use data, we first must create a database with the following metadata:

- **Configuration** read from the sample configuration file
- **Coordinates** built from the configuration
- **Periods** built from the configuration
- **LULC Metadata** describing the land use/land cover classes we will use

## Setup

We retrieve the path of the `evoland` default configuration; for your own work, you would likely copy it to your working directory and adapt it.
The database connection will only be closed once the db object is removed from the workspace and garbage collected (i.e. `rm(db); gc()`); this means there will be a lock on the database, even for reading!

Also, let's make sure the provider is Arealstatistik.
Because the AS is in EPSG:2056 and the sampling relies on a raw coordinate matrix without CRS info, let's make sure we're working in the same CRS.

```{r}
library(evoland)

# new database file. schema gets auto-applied.
db <- evoland_db$new(path = "arealstatistik-model.duckdb")
```

## Construct Coordinate Set

Now that we've read the configuration into the database, it's time to construct a set of coordinate points.
The essential part of the table that we'll use later to build a correct sample of land use classes corresponding to the coordinate point IDs is also built.

```{r}
db$set_coords(
  type = "square",
  epsg = 2056,
  extent = terra::ext(c(
    xmin = 2697000,
    xmax = 2698000,
    ymin = 1252000,
    ymax = 1253000
  )),
  resolution = 100
)
minimal_coords_t <- db$coords_t[, .(id_coord, lon, lat)]
```

## Retrieve Data

Let's read the data sources referenced in the configuration and download them to the directory at `getOption("evoland.cachedir")`.
This is read on package load from the `EVOLAND_CACHEDIR` environment variable, defaulting to `~/evoland-cache`.

```{r}
lulc_files <-
  data.frame(
    url = "https://dam-api.bfs.admin.ch/hub/api/dam/assets/32376216/appendix",
    md5sum = "c32937eb4a11fc9c5c58c66e9830360a"
  ) |>
  download_and_verify()

db$commit(
  data.frame(
    key = c("lulc_data_url", "lulc_data_md5sum", "lulc_data_provider"),
    value = c(lulc_files$url, lulc_files$md5sum, "BFS Arealstatistik")
  ),
  table_name = "reporting_t",
  mode = "append"
)

zippath <- file.path(
  getOption("evoland.cachedir"),
  lulc_files$md5sum,
  lulc_files$local_filename
)

# find singular csv
csv_file <-
  unzip(zippath, list = TRUE) |>
  purrr::pluck("Name") |>
  stringi::stri_subset_fixed(".csv")
stopifnot(length(csv_file) == 1L)
```

## Read Data

Now that we have the file and know the name of the contained CSV file, let's read it into a data.table.
The columns matching with `AS[0-9]{2}_72` indicate the land use / land cover in one of the 72 classes of
The columns starting with `FJ` indicate the flight year for each respective AS period.

```{r}
csv_con <- unz(zippath, csv_file, open = "r")
arealstat_dt <-
  readLines(csv_con) |>
  data.table::fread(
    text = _,
    # selecting only years 1985-2018 for now; Arealstatistik 2025 is not yet finished
    select = c(
      "E_COORD",
      "N_COORD",
      "FJ85",
      "FJ97",
      "FJ09",
      "FJ18",
      # "FJ25",
      "AS85_72",
      "AS97_72",
      "AS09_72",
      "AS18_72"
      # "AS25_72"
    )
  )
close(csv_con)
```

## Recode LULC Classes

The configuration file contains a section declaring the land use classes that are to be used in a simulation.
Each class contains a `src_classes` field, which we'll now make use of to recode the source material to our internal classification system.

```{r}
# create lookup table to aggregate arealstatistik (AS) ids to id_lulc
db$lulc_meta_t <- create_lulc_meta_t(
  list(
    closed_forest = list(
      pretty_name = "Dense Forest",
      description = "Normal forest; Forest strips; Afforestations; Felling areas; Brush forest",
      src_classes = c(50:53, 57L)
    ),
    arable = list(pretty_name = "Arable Land", src_classes = 41L),
    urban = list(
      pretty_name = "Urban areas",
      description = "Industrial and commercial buildings; Surroundings of industrial and commercial buildings; One- and two-family houses; Surroundings of one- and two-family houses; Terraced houses; Surroundings of terraced houses; Blocks of flats; Surroundings of blocks of flats; Public buildings; Surroundings of public buildings; Agricultural buildings; Surroundings of agricultural buildings; Unspecified buildings; Surroundings of unspecified buildings; Parking areas; Construction sites; Unexploited urban areas; Public parks; Sports facilities; Golf courses; Camping areas; Garden allotments; Cemeteries",
      src_classes = c(1:14, 19L, 29:36)
    ),
    static = list(
      pretty_name = "Static / immutable classes",
      description = "Motorways; Green motorway environs; Roads and paths; Green road environs;  Sealed railway areas; Green railway environs;  Airports; Airfields, green airport environs;  Energy supply plants; Waste water treatment plants; Other supply or waste treatment plants; Dumps; Quarries, mines;  Lakes; Rivers; Flood protection structures; Avalanche and rockfall barriers;  Wetlands; Alpine sports facilities; Rocks; Screes, sand; Landscape interventions",
      src_classes = c(15:18, 20:28, 61:63, 66:71)
    )
  )
)

lulc_meta_t <- db$lulc_meta_long_v[, .(id_lulc, AS = src_class)]

# longer form: arealstatistik replaced by id_lulc, flightyear
lulc_fy_dt <-
  data.table::melt(
    # pivot longer with year from regex and coords as ID columns
    arealstat_dt,
    id.vars = c("E_COORD", "N_COORD"),
    measure.vars = data.table::measure(
      value.name, # first match group to columns
      year = as.integer, # second match group to single column
      pattern = "(^FJ|AS)([0-9]{2})"
    )
  )[
    ,
    year := ifelse(year > 84L, year + 1900L, year + 2000L)
  ][
    lulc_meta_t,
    .(
      x = E_COORD,
      y = N_COORD,
      year,
      flightyear = FJ,
      id_lulc
    ),
    on = "AS",
    nomatch = NULL
  ]
```

## Rasterize and Sample

We want to take advantage of the spatial structure of the data to extract the coordinate values of the Arealstatistik at the points where our coordinates are declared.
Hence, we rasterize the tabular data into a multilayer `terra::rast` object.

```{r}
# data.table that can be coerced to multilayer terra::rast using type = "xylz"
layerized_dt <-
  data.table::melt(
    lulc_fy_dt,
    id.vars = c("x", "y", "year")
  )[
    ,
    layer := paste(year, variable, sep = "_")
  ]
data.table::setkey(layerized_dt, layer, x, y)

r <-
  terra::rast(
    layerized_dt[, .(x, y, layer, value)],
    type = "xylz",
    crs = "EPSG:2056"
  ) |>
  terra::as.int() # necessary because terra::rast casts to numeric?
```

Now we have an ndarray with spatial properties, let's use extract and some pivoting magic to coerce these data into a table with an `id_coord, id_lulc, date` tuple.

```{r}
id_coord_var_dt <-
  terra::extract(
    x = r,
    y = as.matrix(minimal_coords_t[, .(lon, lat)]),
    method = "simple"
  ) |>
  data.table::as.data.table() |>
  cbind(id_coord = minimal_coords_t[["id_coord"]]) |>
  data.table::melt(
    id.vars = "id_coord",
    measure.vars = data.table::measure(
      year = as.integer,
      value.name,
      pattern = "([0-9]{4})_(.*)"
    )
  ) |>
  na.omit(cols = c("id_lulc", "flightyear")) |>
  data.table::setnames(
    old = c("year", "flightyear"),
    new = c("period_date", "date")
  )

```

## Associate with Regular Periods

Since our land use change model runs in discrete time and our original land use data may not be in a regular time series, we here associate each `id_coord, id_lulc` tuple with a regular discrete `id_period`, built from the `periods` section of the settings.
For now, the join condition (left closed) is only codified here and in the wiki. Making this canonical will save future modellers headaches.

```{r}
# setup transition periods
db$periods_t <- periods_t <- create_periods_t(
  period_length_str = "P10Y",
  start_observed = "1985-01-01",
  end_observed = "2020-01-01",
  end_extrapolated = "2060-01-01"
)

# build date objects from years. use 1st of january
id_coord_var_dt[
  ,
  `:=`(
    period_date = data.table::as.IDate(paste0(period_date, "-01-01")),
    date = data.table::as.IDate(paste0(date, "-01-01"))
  )
]

lulc_data_t <-
  as_lulc_data_t(
    id_coord_var_dt[
      periods_t,
      .(
        id_coord,
        id_lulc,
        id_period,
        date
      ),
      on = .(
        # left closed interval
        period_date >= start_date,
        period_date < end_date
      ),
      nomatch = NULL
    ]
  )

```

## Finalize: Ingest

Now that we have the data prepared and validated in the correct format, we upsert them into the database:

```{r}
db$lulc_data_t <- lulc_data_t
rm(db)
gc() # close out the database connection / file lock
```
